# Broker端参数

## 存储信息

```shell
log.dirs
log.dir
```

只需要设置log.dirs即可，而且要设置多个路径，使用逗号分隔

eg: /home/kafka1,/home/kafka2,/home/kafka3

> 有条件的话最好保证这些目录挂载到不同的物理磁盘上。这样做有两个好处:
>
> - 提升读写性能:比起单块磁盘，多块物理磁盘同时读写数据有更高的吞吐量。
> - 能够实现故障转移:即Failover。这是Kafka 1.1版本新引入的强大功能。要知道在以前，只要Kafka Broker使用的任何一块磁盘挂掉了，整个Broker进程都会关闭。但是自1.1开始，这种情况被修正了，坏 掉的磁盘上的数据会自动地转移到其他正常的磁盘上，而且Broker还能正常工作。



## zookeeper相关

ZooKeeper是做什么的呢?

它是一个分布式协调框架，负责协调管理并保存Kafka集群的所有元数据信息，比如集群都有哪些Broker在运行、创建了哪些Topic，每个Topic都有多少分区以及这些分区的Leader副本都在哪些机器上等信息。

```shell
zookeeper.connect
```

> 1. 使用逗号设置多个值
>
> eg:zk1:2181,zk2:2181,zk3:2181
>
> 2. 多个kafka集群共用一套zookeeper集群
>
> zk1:2181,zk2:2181,zk3:2181/kafka1
> 和 
> zk1:2181,zk2:2181,zk3:2181/kafka2



## 与其他组件的连接配置

与Broker连接相关的，即客户端程序或其他Broker如何与该Broker进行通信的设置。有以下
三个参数:

```shell
listeners:学名叫监听器，其实就是告诉外部连接者要通过什么协议访问指定主机名和端口开放的 Kafka服务。
advertised.listeners:和listeners相比多了个advertised。Advertised的含义表示宣称的、公布的，就是说这组监听器是Broker用于对外发布的。
host.name/port:过期参数，无需指定
```

## Topic管理

```shell
auto.create.topics.enable:是否允许自动创建Topic。 
unclean.leader.election.enable:是否允许Unclean Leader选举。 
auto.leader.rebalance.enable:是否允许定期进行Leader选举。
```

> 1. auto.create.topics.enable 建议设置成false 
>
>    Eg: 你可能有这样的经历，要为名为test的Topic发送事件，但是不小心拼写错误了，把test写成了tst，之后启动了生产者程序。恭喜你，一个名为tst的Topic就被自动创建了。 
>
> 2. 如果设置成false，坚决不能让那些落后太多的副本竞选Leader。这样做的后果是这个分区就不可用了，因为没有Leader了。反之如果是true，那么Kafka允许你从那些“跑得慢”的副本中选一个出来当Leader。这样做的后果是数据有可能就丢失了
>
> 3. 设置它的值为true表示允许Kafka定期地对一些Topic分区进行Leader重选举，换一次Leader代价很高的，原本向A发送请求的所有客户端都要切换成向B发送请求，而且这种换 Leader本质上没有任何性能收益，因此建议在生产环境中把这个参数设置成false。 



## 数据留存相关参数

```shell
log.retention.{hour|minutes|ms}:这是个“三兄弟”，都是控制一条消息数据被保存多长时间。从优先级上来说ms设置最高、minutes次之、hour最低。
log.retention.bytes:这是指定Broker为消息保存的总磁盘容量大小。 
message.max.bytes:控制Broker能够接收的最大消息大小。
```







# Topic级别参数

> topic级别参数与broker全局级别参数
>
> topic级别参数优先级更高，会覆盖broker全局级别参数



```shell
retention.ms:规定了该Topic消息被保存的时长。默认是7天，即该Topic只保存最近7天的消息。一旦 设置了这个值，它会覆盖掉Broker端的全局参数值。

retention.bytes:规定了要为该Topic预留多大的磁盘空间。和全局参数作用相似，这个值通常在多 租户的Kafka集群中会有用武之地。当前默认值是-1，表示可以无限使用磁盘空间。
```





# JVM参数

>  Kafka服务端代码是用scala语言编写的，最终编译成字节码在jvm上运行

通用建议：

1. 堆大小

> Kafka Broker在与客户端
> 进行交互时会在JVM堆上创建大量的ByteBuffer实例，Heap Size不能太小

2. 垃圾回收
   - Java7
     - 如果Broker所在机器的CPU资源非常充裕，建议使用CMS收集器。启用方法是指定- XX:+UseCurrentMarkSweepGC。 
     - 否则，使用吞吐量收集器。开启方法是指定-XX:+UseParallelGC。

   - Java8
     - 使用G1



如何设置jvm参数？

设置下面这两个环境变量即可

- KAFKA_HEAP_OPTS:指定堆大小。
- KAFKA_JVM_PERFORMANCE_OPTS:指定GC参数。

```shell
# 可以这样启动Kafka Broker，即在启动Kafka Broker之前，先设置上这两个环境变量:
$> export KAFKA_HEAP_OPTS=--Xms6g --Xmx6g
$> export KAFKA_JVM_PERFORMANCE_OPTS= -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=3 
$> bin/kafka-server-start.sh config/server.properties
```



# 操作系统参数

这几个参数需要注意一下：

1. 文件描述符限制

> ulimit -n
>
> 任何一个Java项目最好都调整下这个值。
>
> 实际上，文件描述符系统资源并不像
> 我们想象的那样昂贵，你不用太担心调大此值会有什么不利的影响。通常情况下将它设置成一个超大的值是
> 合理的做法，比如ulimit -n 1000000。
>
> 其实设置这个参数一点都不重要，但
> 不设置的话后果很严重，比如你会经常看到“Too many open files”的错误。

- 文件系统类型

> 文件系统类型的选择。这里所说的文件系统指的是如ext3、ext4或XFS这样的日志型文件系统。根据
> 官网的测试报告，XFS的性能要强于ext4，所以生产环境最好还是使用XFS。
>
> Kafka使用ZFS的数据报告，性能更加强劲:https://www.confluent.io/kafka-summit-sf18/kafka-on-zfs

- Swappiness

> 网上很多文章都提到设置其为0，将swap完全禁掉以防止Kafka进程使用swap空间。我
> 个人反倒觉得还是不要设置成0比较好，我们可以设置成一个较小的值。为什么呢?因为一旦设置成0，当
> 物理内存耗尽时，操作系统会触发OOM killer这个组件，它会随机挑选一个进程然后kill掉，即根本不给用
> 户任何的预警。但如果设置成一个比较小的值，当开始使用swap空间时，你至少能够观测到Broker性能开
> 始出现急剧下降，从而给你进一步调优和诊断问题的时间。基于这个考虑，个人建议将swappniess配置
> 成一个接近0但不为0的值，比如1。

- 将内存buffer刷到磁盘的时间间隔

> 向Kafka发送数据并不是真要等数据被写入磁盘才会认为成功，而
> 是只要数据被写入到操作系统的页缓存(Page Cache)上就可以了，随后操作系统根据LRU算法会定期将页
> 缓存上的“脏”数据落盘到物理磁盘上。这个定期就是由提交时间来确定的，默认是5秒。一般情况下我们
> 会认为这个时间太频繁了，可以适当地增加提交间隔来降低物理磁盘的写操作。当然你可能会有这样的疑
> 问:如果在页缓存中的数据在写入到磁盘前机器宕机了，那岂不是数据就丢失了。的确，这种情况数据确实
> 就丢失了，但鉴于Kafka在软件层面已经提供了多副本的冗余机制，因此这里稍微拉大提交间隔去换取性能
> 还是一个合理的做法。

